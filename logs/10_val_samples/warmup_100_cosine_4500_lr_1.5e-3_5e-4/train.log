Arguments: Namespace(train_data='../data/TinyStoriesV2-GPT4-train.txt', val_data='../data/TinyStoriesV2-GPT4-valid.txt', log_dir='../logs/10/warmup_100_cosine_4500_lr_1.5e-3_5e-4', checkpoint_dir='../ckpt/10/warmup_100_cosine_4500_lr_1.5e-3_5e-4', checkpoint_interval=1000, checkpoint_resume_path='', eval_interval=100, num_layers=4, d_model=512, num_heads=16, d_ff=1344, max_seq_length=256, batch_size=32, num_epochs=5000, rope_theta=10000, adamw_beta1=0.9, adamw_beta2=0.999, adamw_eps=1e-08, adamw_weight_decay=0.01, lr=0.001, enable_lr_schedule=True, lr_max=0.0015, lr_min=0.0005, warmup_iters=100, cosine_iters=4500, max_grad_norm=1.0, seed=599)
using device: cuda:0
loading data...
Starting training from epoch 0
Epoch 100, Training Loss: 3.6274, Validation Loss: 3.5715
Epoch 200, Training Loss: 2.8955, Validation Loss: 2.9144
Epoch 300, Training Loss: 2.6255, Validation Loss: 2.6497
Epoch 400, Training Loss: 2.5025, Validation Loss: 2.5140
Epoch 500, Training Loss: 2.4942, Validation Loss: 2.4122
Epoch 600, Training Loss: 2.3191, Validation Loss: 2.3343
Epoch 700, Training Loss: 2.3606, Validation Loss: 2.2751
Epoch 800, Training Loss: 2.1776, Validation Loss: 2.2151
Epoch 900, Training Loss: 2.2519, Validation Loss: 2.1648
Saved checkpoint to ../ckpt/10/warmup_100_cosine_4500_lr_1.5e-3_5e-4/ckpt1000.pt
Epoch 1000, Training Loss: 2.2246, Validation Loss: 2.1311
Epoch 1100, Training Loss: 2.0446, Validation Loss: 2.0961
Epoch 1200, Training Loss: 2.0765, Validation Loss: 2.0687
Epoch 1300, Training Loss: 1.9335, Validation Loss: 2.0400
Epoch 1400, Training Loss: 2.0283, Validation Loss: 2.0246
Epoch 1500, Training Loss: 1.9612, Validation Loss: 1.9929
Epoch 1600, Training Loss: 2.0110, Validation Loss: 1.9759
Epoch 1700, Training Loss: 1.9297, Validation Loss: 1.9512
Epoch 1800, Training Loss: 1.8937, Validation Loss: 1.9313
Epoch 1900, Training Loss: 1.8318, Validation Loss: 1.9199
Saved checkpoint to ../ckpt/10/warmup_100_cosine_4500_lr_1.5e-3_5e-4/ckpt2000.pt
Epoch 2000, Training Loss: 1.9356, Validation Loss: 1.8975
Epoch 2100, Training Loss: 1.8437, Validation Loss: 1.8813
Epoch 2200, Training Loss: 1.8396, Validation Loss: 1.8674
Epoch 2300, Training Loss: 1.7166, Validation Loss: 1.8575
Epoch 2400, Training Loss: 1.7527, Validation Loss: 1.8402
Epoch 2500, Training Loss: 1.7310, Validation Loss: 1.8252
Epoch 2600, Training Loss: 1.7824, Validation Loss: 1.8143
Epoch 2700, Training Loss: 1.8501, Validation Loss: 1.8053
Epoch 2800, Training Loss: 1.7455, Validation Loss: 1.7930
Epoch 2900, Training Loss: 1.7351, Validation Loss: 1.7802
Saved checkpoint to ../ckpt/10/warmup_100_cosine_4500_lr_1.5e-3_5e-4/ckpt3000.pt
Epoch 3000, Training Loss: 1.7410, Validation Loss: 1.7699
Epoch 3100, Training Loss: 1.7649, Validation Loss: 1.7613
Epoch 3200, Training Loss: 1.7466, Validation Loss: 1.7547
Epoch 3300, Training Loss: 1.7898, Validation Loss: 1.7434
Epoch 3400, Training Loss: 1.8078, Validation Loss: 1.7343
Epoch 3500, Training Loss: 1.6005, Validation Loss: 1.7259
Epoch 3600, Training Loss: 1.7515, Validation Loss: 1.7204
Epoch 3700, Training Loss: 1.7412, Validation Loss: 1.7134
Epoch 3800, Training Loss: 1.5731, Validation Loss: 1.7069
Epoch 3900, Training Loss: 1.6340, Validation Loss: 1.6988
Saved checkpoint to ../ckpt/10/warmup_100_cosine_4500_lr_1.5e-3_5e-4/ckpt4000.pt
Epoch 4000, Training Loss: 1.6998, Validation Loss: 1.6957
Epoch 4100, Training Loss: 1.7298, Validation Loss: 1.6898
Epoch 4200, Training Loss: 1.7121, Validation Loss: 1.6873
Epoch 4300, Training Loss: 1.6768, Validation Loss: 1.6824
Epoch 4400, Training Loss: 1.6694, Validation Loss: 1.6749
Epoch 4500, Training Loss: 1.6484, Validation Loss: 1.6729
Epoch 4600, Training Loss: 1.5679, Validation Loss: 1.6689
Epoch 4700, Training Loss: 1.6584, Validation Loss: 1.6664
Epoch 4800, Training Loss: 1.6345, Validation Loss: 1.6632
Epoch 4900, Training Loss: 1.5700, Validation Loss: 1.6630
Saved checkpoint to ../ckpt/10/warmup_100_cosine_4500_lr_1.5e-3_5e-4/ckpt5000.pt
Epoch 5000, Training Loss: 1.6484, Validation Loss: 1.6552
